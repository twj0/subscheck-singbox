#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SubsCheck-Ubuntu: åŸºäºSing-boxçš„ä»£ç†èŠ‚ç‚¹æµ‹é€Ÿå·¥å…·
twj0 | 3150774524@qq.com
ä¸“ä¸ºä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒè®¾è®¡ï¼Œä½¿ç”¨åŸç”Ÿåè®®æµ‹è¯•èŠ‚ç‚¹è¿é€šæ€§
"""

import asyncio
import argparse
import yaml
import aiohttp
import time
import schedule
import pytz
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime, time as dt_time
import json
from dotenv import load_dotenv

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from utils.logger import setup_logger, get_logger, log_pwsh_command
from parsers.base_parser import parse_node_url
from parsers.clash_parser import parse_clash_config
from testers.node_tester import NodeTester
from utils.subscription_backup import SubscriptionBackup
from utils.uploader import ResultUploader

class SubsCheckUbuntu:
    """
    SubsCheck-Ubuntu ä¸»ç±»
    ä½¿ç”¨ Sing-box ä½œä¸ºä»£ç†æ ¸å¿ƒè¿›è¡Œé«˜æ€§èƒ½èŠ‚ç‚¹æµ‹è¯•
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.tester = NodeTester(config)
        # è·å–å½“å‰çš„æ—¥å¿—å™¨å®ä¾‹
        from utils.logger import get_logger
        self.log = get_logger()
        
    async def fetch_subscription_content(self, url: str, retry_count: int = 3) -> str:
        """è·å–è®¢é˜…å†…å®¹ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        for attempt in range(retry_count):
            try:
                timeout = aiohttp.ClientTimeout(
                    total=30,  # å¢åŠ æ€»è¶…æ—¶æ—¶é—´
                    connect=15,  # è¿æ¥è¶…æ—¶
                    sock_read=15  # è¯»å–è¶…æ—¶
                )
                headers = {
                    'User-Agent': self.config['network']['user_agent'],
                    'Accept': '*/*',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive'
                }
                
                # ä½¿ç”¨æ›´é€‚åˆçš„è¿æ¥å™¨é…ç½®
                connector = aiohttp.TCPConnector(
                    limit=30,
                    limit_per_host=10,
                    ttl_dns_cache=300,
                    use_dns_cache=True,
                    enable_cleanup_closed=True
                )
                
                async with aiohttp.ClientSession(
                    connector=connector, 
                    timeout=timeout,
                    trust_env=True  # ä½¿ç”¨ç³»ç»Ÿä»£ç†è®¾ç½®
                ) as session:
                    async with session.get(url, headers=headers) as response:
                        if response.status == 200:
                            content = await response.text(encoding='utf-8', errors='ignore')
                            self.log.info(f"è®¢é˜…è·å–æˆåŠŸ: {url[:50]}...")
                            return content
                        elif response.status in [301, 302, 303, 307, 308]:
                            # å¤„ç†é‡å®šå‘
                            redirect_url = response.headers.get('Location')
                            if redirect_url and attempt == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•é‡å®šå‘
                                self.log.info(f"è®¢é˜…è¢«é‡å®šå‘åˆ°: {redirect_url}")
                                return await self.fetch_subscription_content(redirect_url, 1)
                        else:
                            self.log.warning(f"è®¢é˜…è¿”å›é”™è¯¯ {response.status}: {url}")
                            
            except asyncio.TimeoutError:
                self.log.error(f"è®¢é˜…è·å–è¶…æ—¶ (attempt {attempt + 1}/{retry_count}): {url[:50]}...")
            except aiohttp.ClientConnectorError as e:
                self.log.error(f"è®¢é˜…è¿æ¥é”™è¯¯ (attempt {attempt + 1}/{retry_count}): {str(e)[:100]}")
            except aiohttp.ClientError as e:
                self.log.error(f"è®¢é˜…å®¢æˆ·ç«¯é”™è¯¯ (attempt {attempt + 1}/{retry_count}): {str(e)[:100]}")
            except Exception as e:
                self.log.error(f"è®¢é˜…è·å–å¤±è´¥ (attempt {attempt + 1}/{retry_count}): {str(e)[:100]}")
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
            if attempt < retry_count - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€è¡¥
                self.log.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)
        
        return ""
    
    def parse_subscription_content(self, content: str) -> List[Dict[str, Any]]:
        """æ™ºèƒ½è§£æè®¢é˜…å†…å®¹"""
        nodes = []
        
        # å°è¯•YAMLè§£æ (Clash æ ¼å¼)
        try:
            config_data = yaml.safe_load(content)
            if isinstance(config_data, dict) and 'proxies' in config_data:
                self.log.info("æ£€æµ‹åˆ°Clash YAMLæ ¼å¼")
                clash_nodes = parse_clash_config(config_data)
                nodes.extend(clash_nodes)
                return nodes
        except Exception:
            pass
        
        # å°è¯•Base64è§£ç 
        try:
            import base64
            decoded = base64.b64decode(content.strip()).decode('utf-8')
            if any(proto in decoded for proto in ['vless://', 'vmess://', 'trojan://', 'ss://']):
                self.log.info("æ£€æµ‹åˆ°Base64ç¼–ç å†…å®¹")
                content = decoded
        except Exception:
            pass
        
        # è§£æé“¾æ¥
        for line in content.strip().split('\n'):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            node = parse_node_url(line)
            if node:
                nodes.append(node)
        
        return nodes
    
    def deduplicate_nodes(self, nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """èŠ‚ç‚¹å»é‡"""
        seen = set()
        unique_nodes = []
        
        for node in nodes:
            try:
                # ä½¿ç”¨æœåŠ¡å™¨ã€ç«¯å£å’Œç±»å‹ä½œä¸ºå”¯ä¸€æ ‡è¯†
                key = (node['server'], node['port'], node['type'])
                if key not in seen:
                    seen.add(key)
                    unique_nodes.append(node)
            except (KeyError, TypeError):
                continue
        
        return unique_nodes
    
    async def test_nodes(self, nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹é‡æµ‹è¯•èŠ‚ç‚¹ï¼ˆå¢å¼ºç¨³å®šæ€§ï¼‰"""
        if not nodes:
            self.log.warning("æ²¡æœ‰èŠ‚ç‚¹å¯ä»¥æµ‹è¯•")
            return []
        
        self.log.info(f"å¼€å§‹æµ‹è¯• {len(nodes)} ä¸ªèŠ‚ç‚¹...")
        
        # æ ¹æ®èŠ‚ç‚¹æ•°é‡åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
        base_concurrency = self.config['test_settings']['concurrency']
        auto_adjust = self.config['test_settings'].get('concurrency_auto_adjust', True)

        if auto_adjust:
            if len(nodes) > 100:
                # å¤§é‡èŠ‚ç‚¹æ—¶é™ä½å¹¶å‘æ•°
                actual_concurrency = max(1, base_concurrency // 2)
                self.log.info(f"æ£€æµ‹åˆ°å¤§é‡èŠ‚ç‚¹ï¼Œæ™ºèƒ½è°ƒæ•´å¹¶å‘æ•°è‡³ {actual_concurrency} ä»¥æé«˜ç¨³å®šæ€§")
            elif len(nodes) < 10:
                # å°‘é‡èŠ‚ç‚¹æ—¶å¯ä»¥æé«˜å¹¶å‘æ•°
                actual_concurrency = min(len(nodes), base_concurrency + 1)
            else:
                actual_concurrency = base_concurrency
        else:
            actual_concurrency = base_concurrency
            self.log.info(f"æ™ºèƒ½å¹¶å‘è°ƒæ•´å·²ç¦ç”¨ï¼Œä½¿ç”¨å›ºå®šå¹¶å‘æ•°: {actual_concurrency}")
        
        # å¹¶å‘æµ‹è¯•
        semaphore = asyncio.Semaphore(actual_concurrency)
        
        async def test_with_limit(node: Dict[str, Any], index: int) -> Dict[str, Any]:
            async with semaphore:
                try:
                    return await self.tester.test_single_node(node, index)
                except Exception as e:
                    self.log.error(f"èŠ‚ç‚¹æµ‹è¯•å¼‚å¸¸ [{index+1}]: {e}")
                    return {
                        'name': node.get('name', 'Unnamed'),
                        'server': node.get('server', 'N/A'),
                        'port': node.get('port', 'N/A'),
                        'type': node.get('type', 'N/A'),
                        'status': 'failed',
                        'error': f'Test exception: {str(e)[:100]}',
                        'http_latency': None,
                        'download_speed': None
                    }
        
        # åˆ›å»ºä»»åŠ¡
        tasks = [test_with_limit(node, i) for i, node in enumerate(nodes)]
        
        # æ‰§è¡Œæµ‹è¯•ï¼ˆå¢åŠ è¿›åº¦æ˜¾ç¤ºï¼‰
        results = []
        completed = 0
        
        # åˆ†æ‰¹æ‰§è¡Œä»¥æé«˜ç¨³å®šæ€§
        batch_size = min(20, len(tasks))  # æ¯æ‰¹æœ€å¤š20ä¸ªä»»åŠ¡
        
        for i in range(0, len(tasks), batch_size):
            batch_tasks = tasks[i:i+batch_size]
            self.log.info(f"æ­£åœ¨æ‰§è¡Œç¬¬ {i//batch_size + 1} æ‰¹æµ‹è¯•ï¼ˆ{len(batch_tasks)} ä¸ªèŠ‚ç‚¹ï¼‰")
            
            try:
                batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                # å¤„ç†ç»“æœ
                for result in batch_results:
                    if isinstance(result, Exception):
                        self.log.error(f"æ‰¹é‡æµ‹è¯•å¼‚å¸¸: {result}")
                        results.append({
                            'name': 'Unknown',
                            'server': 'N/A',
                            'port': 'N/A', 
                            'type': 'N/A',
                            'status': 'failed',
                            'error': f'Batch test exception: {str(result)[:100]}',
                            'http_latency': None,
                            'download_speed': None
                        })
                    else:
                        results.append(result)
                    
                completed += len(batch_tasks)
                self.log.info(f"æµ‹è¯•è¿›åº¦: {completed}/{len(nodes)} ({completed/len(nodes)*100:.1f}%)")
                
                # æ‰¹æ¬¡é—´éš”ç¨ä½œç­‰å¾…ï¼Œå‡å°‘ç³»ç»Ÿè´Ÿè½½
                if i + batch_size < len(tasks):
                    await asyncio.sleep(1)
                    
            except Exception as e:
                self.log.error(f"æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
                continue
        
        return results
    
    def save_results(self, results: List[Dict[str, Any]]) -> str:
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        results_dir = Path(self.config['output']['results_dir'])
        results_dir.mkdir(exist_ok=True)
        
        # ç­›é€‰æˆåŠŸçš„ç»“æœå¹¶æŒ‰ä¸‹è½½é€Ÿåº¦æ’åºï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰
        success_results = [r for r in results if r['status'] == 'success']
        # æŒ‰ä¸‹è½½é€Ÿåº¦é™åºæ’åˆ—ï¼ˆé€Ÿåº¦è¶Šå¿«è¶Šå¥½ï¼‰
        success_results.sort(key=lambda x: x.get('download_speed') or 0, reverse=True)
        
        # ç”Ÿæˆç»“æœæ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = results_dir / f"subscheck_results_{timestamp}.json"
        
        result_data = {
            'timestamp': datetime.now().isoformat(),
            'total_tested': len(results),
            'success_count': len(success_results),
            'success_rate': f"{len(success_results)/len(results)*100:.1f}%" if results else "0%",
            'test_config': {
                'max_nodes': self.config['test_settings']['max_test_nodes'],
                'concurrency': self.config['test_settings']['concurrency'],
                'timeout': self.config['test_settings']['timeout']
            },
            'top_nodes': success_results[:self.config['output']['show_top_nodes']],
            'all_results': results if self.config['output']['save_all_results'] else success_results
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
        
        self.log.info(f"ç»“æœå·²ä¿å­˜: {filename}")
        return str(filename)
    
    def display_results(self, results: List[Dict[str, Any]]):
        """æ˜¾ç¤ºæµ‹è¯•ç»“æœ"""
        success_results = [r for r in results if r['status'] == 'success']
        
        if not success_results:
            self.log.warning("æ²¡æœ‰æˆåŠŸçš„èŠ‚ç‚¹")
            return
        
        # æŒ‰ä¸‹è½½é€Ÿåº¦æ’åºï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰
        success_results.sort(key=lambda x: x.get('download_speed') or 0, reverse=True)
        
        print(f"\n{'=' * 80}")
        print(f"æµ‹è¯•ç»“æœç»Ÿè®¡")
        print(f"{'=' * 80}")
        print(f"æ€»æµ‹è¯•èŠ‚ç‚¹: {len(results)}")
        print(f"æˆåŠŸèŠ‚ç‚¹: {len(success_results)}")
        print(f"æˆåŠŸç‡: {len(success_results)/len(results)*100:.1f}%")
        
        # æ˜¾ç¤ºæœ€ä½³èŠ‚ç‚¹
        show_count = min(self.config['output']['show_top_nodes'], len(success_results))
        if show_count > 0:
            print(f"\næœ€ä½³èŠ‚ç‚¹ (æŒ‰é€Ÿåº¦æ’åå‰{show_count}ä¸ª):")
            print(f"{'-' * 80}")
            print(f"{'#':<3} {'Name':<30} {'Speed':<15} {'Latency':<10} {'IP Purity':<15} {'Server':<20}")
            print(f"{'-' * 95}")
            
            for i, node in enumerate(success_results[:show_count]):
                # æ ¹æ“šé€Ÿåº¦å¤§å°é¸æ“‡åˆé©çš„ç²¾åº¦é¡¯ç¤º
                if node.get('download_speed'):
                    speed_val = node.get('download_speed', 0)
                    if speed_val >= 1:
                        speed = f"{speed_val:.2f}Mbps"
                    elif speed_val >= 0.1:
                        speed = f"{speed_val:.3f}Mbps"
                    else:
                        speed = f"{speed_val:.6f}Mbps"
                else:
                    speed = "N/A"
                latency = f"{node.get('http_latency', 0):.0f}ms" if node.get('http_latency') else "N/A"
                ip_purity = node.get('ip_purity', 'N/A') or "N/A"
                print(f"{i+1:<3} {node['name'][:29]:<30} {speed:<15} {latency:<10} {ip_purity:<15} {node['server']:<20}")
    
    async def run(self, subscription_file: str):
        """ä¸»è¿è¡Œæµç¨‹"""
        start_time = time.time()
        
        self.log.info("=" * 60)
        self.log.info("SubsCheck-Ubuntu v1.0 - åŸºäºSing-boxçš„ä»£ç†èŠ‚ç‚¹æµ‹é€Ÿå·¥å…·")
        self.log.info("=" * 60)
        
        # æ£€æŸ¥è®¢é˜…æ–‡ä»¶
        sub_file = Path(subscription_file)
        if not sub_file.exists():
            self.log.error(f"è®¢é˜…æ–‡ä»¶ä¸å­˜åœ¨: {subscription_file}")
            return
        
        # è¯»å–è®¢é˜…é“¾æ¥
        with open(sub_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        
        self.log.info(f"å‘ç° {len(urls)} ä¸ªè®¢é˜…é“¾æ¥")
        
        if not urls:
            self.log.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®¢é˜…é“¾æ¥")
            return
        
        # è·å–æ‰€æœ‰èŠ‚ç‚¹
        all_nodes = []
        for i, url in enumerate(urls, 1):
            self.log.info(f"æ­£åœ¨è·å–è®¢é˜… {i}/{len(urls)}: {url[:50]}...")
            content = await self.fetch_subscription_content(url)
            if content:
                nodes = self.parse_subscription_content(content)
                all_nodes.extend(nodes)
                self.log.info(f"ä»è®¢é˜…è§£æåˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹")
        
        if not all_nodes:
            self.log.error("æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆèŠ‚ç‚¹")
            return
        
        # å»é‡
        unique_nodes = self.deduplicate_nodes(all_nodes)
        self.log.info(f"å»é‡åå…± {len(unique_nodes)} ä¸ªèŠ‚ç‚¹")
        
        # é™åˆ¶æµ‹è¯•æ•°é‡ï¼ˆå¦‚æœé…ç½®äº†çš„è¯ï¼‰
        max_test_nodes = self.config.get('test_settings', {}).get('max_test_nodes')
        if max_test_nodes and max_test_nodes > 0 and len(unique_nodes) > max_test_nodes:
            unique_nodes = unique_nodes[:max_test_nodes]
            self.log.info(f"é™åˆ¶æµ‹è¯•èŠ‚ç‚¹æ•°é‡ä¸º {max_test_nodes}")
        else:
            self.log.info(f"å°†æµ‹è¯•æ‰€æœ‰ {len(unique_nodes)} ä¸ªèŠ‚ç‚¹ï¼ˆæœªè®¾ç½®èŠ‚ç‚¹æ•°é‡é™åˆ¶ï¼‰")
        
        try:
            # æµ‹è¯•èŠ‚ç‚¹
            results = await self.test_nodes(unique_nodes)
            
            # æ˜¾ç¤ºç»“æœ
            self.display_results(results)
            
            # ä¿å­˜ç»“æœ
            result_file = self.save_results(results)
            
            # ç»Ÿè®¡
            end_time = time.time()
            duration = end_time - start_time
            success_count = len([r for r in results if r['status'] == 'success'])
            
            self.log.info(f"\næµ‹è¯•å®Œæˆ! è€—æ—¶: {duration:.1f}s, æˆåŠŸ: {success_count}/{len(results)}")
            
            # ä¸Šä¼ æµ‹è¯•ç»“æœ
            if self.config.get('upload_settings', {}).get('enabled', False):
                self.log.info("å¼€å§‹ä¸Šä¼ æµ‹è¯•ç»“æœ...")
                result_uploader = ResultUploader(self.config)
                await result_uploader.upload_results(results, len(unique_nodes))

            # å¤‡ä»½è®¢é˜…
            if self.config.get('subscription_backup', {}).get('enabled', False):
                self.log.info("å¼€å§‹å¤‡ä»½æˆåŠŸçš„èŠ‚ç‚¹...")
                backup_module = SubscriptionBackup(self.config)
                successful_nodes = [r for r in results if r['status'] == 'success']
                await backup_module.backup_subscription(successful_nodes)
            
        finally:
            # æ¸…ç†èµ„æº
            await self.tester.cleanup()

def load_config(config_file: str = 'config.yaml') -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶å¹¶è§£æç¯å¢ƒå˜é‡"""
    from utils.logger import get_logger
    from utils.config_utils import parse_env_variables
    log = get_logger()
    
    config_path = Path(config_file)
    if not config_path.exists():
        log.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
        
    # è§£æç¯å¢ƒå˜é‡
    config = parse_env_variables(config)
    
    log.info(f"é…ç½®åŠ è½½æˆåŠŸ: {config_file}")
    return config

async def run_speed_test(config_file: str, subscription_file: str, max_nodes: int = None, debug: bool = False):
    """æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æµ‹é€Ÿä»»åŠ¡"""
    from utils.logger import setup_logger, get_logger
    
    # è®¾ç½®æ—¥å¿—
    setup_logger(debug_mode=debug, debug_dir='debug')
    log = get_logger()
    
    try:
        log.info("=" * 60)
        log.info("å¼€å§‹æ‰§è¡Œå®šæ—¶æµ‹é€Ÿä»»åŠ¡")
        log.info(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log.info("=" * 60)
        
        # åŠ è½½é…ç½®
        config = load_config(config_file)
        
        # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
        if max_nodes:
            config['test_settings']['max_test_nodes'] = max_nodes
        
        # åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•å™¨
        checker = SubsCheckUbuntu(config)
        await checker.run(subscription_file)
        
        log.info("å®šæ—¶æµ‹é€Ÿä»»åŠ¡å®Œæˆ")
        
    except Exception as e:
        log.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        raise

def schedule_job(config: Dict[str, Any]):
    """å®šæ—¶ä»»åŠ¡çš„åŒ…è£…å‡½æ•°"""
    # ä½¿ç”¨ä¼ å…¥çš„é…ç½®
    scheduler_config = config.get('scheduler', {})
    asyncio.run(run_speed_test(
        config_file='config.yaml',
        subscription_file='subscription.txt',
        max_nodes=config.get('test_settings', {}).get('max_test_nodes'),
        debug=False
    ))

def start_scheduler(config: Dict[str, Any]):
    """å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
    from utils.logger import setup_logger, get_logger
    
    # è®¾ç½®æ—¥å¿—
    setup_logger(debug_mode=False, debug_dir='debug')
    log = get_logger()
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–å®šæ—¶ä»»åŠ¡è®¾ç½®
    scheduler_config = config.get('scheduler', {})
    
    if not scheduler_config.get('enabled', False):
        log.warning("ğŸš« å®šæ—¶ä»»åŠ¡æœªåœ¨é…ç½®ä¸­å¯ç”¨")
        return
    
    # è·å–æ—¶é—´è®¾ç½®
    schedule_time = scheduler_config.get('time', '20:00')  # é»˜è®¤ä¸­å›½æ—¶é—´20ç‚¹
    timezone_name = scheduler_config.get('timezone', 'Asia/Shanghai')
    is_daily = scheduler_config.get('daily', True)
    
    try:
        # è®¾ç½®æ—¶åŒº
        tz = pytz.timezone(timezone_name)
        
        # è§£ææ—¶é—´
        hour, minute = map(int, schedule_time.split(':'))
        
        # è®¡ç®—UTCæ—¶é—´ï¼ˆç”¨äºScheduleåº“ï¼‰
        # åˆ›å»ºä¸€ä¸ªä»Šå¤©çš„datetimeå¯¹è±¡
        local_dt = tz.localize(datetime.now().replace(hour=hour, minute=minute, second=0, microsecond=0))
        utc_dt = local_dt.astimezone(pytz.UTC)
        utc_time_str = utc_dt.strftime('%H:%M')
        
        log.info(f"ğŸ•‘ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
        log.info(f"ğŸ“… æ‰§è¡Œæ—¶é—´: æ¯å¤© {schedule_time} ({timezone_name})")
        log.info(f"ğŸŒ UTCæ—¶é—´: {utc_time_str}")
        log.info(f"ğŸšª æŒ‰ Ctrl+C åœæ­¢è°ƒåº¦å™¨")
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼ˆä½¿ç”¨UTCæ—¶é—´ï¼‰
        if is_daily:
            schedule.every().day.at(utc_time_str).do(lambda: schedule_job(config))
        
        # ç«‹å³æ£€æŸ¥æ˜¯å¦å·²ç»åˆ°äº†æ‰§è¡Œæ—¶é—´
        now_utc = datetime.now(pytz.UTC)
        if now_utc.hour == utc_dt.hour and now_utc.minute == utc_dt.minute:
            log.info("ğŸš€ å½“å‰æ—¶é—´æ­£å¥½æ˜¯æ‰§è¡Œæ—¶é—´ï¼Œç«‹å³æ‰§è¡Œä¸€æ¬¡")
            schedule_job(config)
        
    except Exception as e:
        log.error(f"æ—¶é—´é…ç½®è§£æå¤±è´¥: {e}")
        log.info("ä½¿ç”¨é»˜è®¤é…ç½®: æ¯å¤©UTC 12:00 (ä¸­å›½æ—¶é—´20:00)")
        schedule.every().day.at("12:00").do(lambda: schedule_job(config))
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        log.info("ğŸ›¡ï¸ ç”¨æˆ·ä¸­æ–­è°ƒåº¦å™¨")

async def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ .env æ–‡ä»¶
    load_dotenv()
    
    parser = argparse.ArgumentParser(
        description="SubsCheck-Ubuntu - åŸºäºSing-boxçš„ä»£ç†èŠ‚ç‚¹æµ‹é€Ÿå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python main.py                           # ä½¿ç”¨é»˜è®¤é…ç½®
  python main.py -s my_subs.txt           # æŒ‡å®šè®¢é˜…æ–‡ä»¶
  python main.py -c custom_config.yaml    # æŒ‡å®šé…ç½®æ–‡ä»¶
  python main.py -n 20                    # é™åˆ¶æµ‹è¯•èŠ‚ç‚¹æ•°
  python main.py --scheduler              # å¯åŠ¨å®šæ—¶ä»»åŠ¡æ¨¡å¼
  python main.py --run-once               # ç«‹å³æ‰§è¡Œä¸€æ¬¡æµ‹è¯•

å®šæ—¶ä»»åŠ¡è®¾ç½®:
  åœ¨ config.yaml ä¸­ä¿®æ”¹ scheduler é…ç½®ï¼š
  scheduler:
    enabled: true
    time: "20:00"             # ä¸­å›½æ—¶é—´
    timezone: "Asia/Shanghai"
    daily: true
        """
    )
    
    parser.add_argument('-s', '--subscription', default='subscription.txt',
                       help="è®¢é˜…æ–‡ä»¶è·¯å¾„ (é»˜è®¤: subscription.txt)")
    parser.add_argument('-c', '--config', default='config.yaml',
                       help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)")
    parser.add_argument('-n', '--max-nodes', type=int,
                       help="æœ€å¤§æµ‹è¯•èŠ‚ç‚¹æ•° (è¦†ç›–é…ç½®æ–‡ä»¶)")
    parser.add_argument('-d', '--debug', action='store_true',
                       help="å¯ç”¨debugæ¨¡å¼ï¼Œè®°å½•è¯¦ç»†æ—¥å¿—å’ŒPowerShellè¾“å‡º")
    parser.add_argument('--debug-dir', default='debug',
                       help="debugæ—¥å¿—æ–‡ä»¶å¤¹ (é»˜è®¤: debug)")
    parser.add_argument('--scheduler', action='store_true',
                       help="å¯ç”¨å®šæ—¶ä»»åŠ¡æ¨¡å¼ï¼Œæ¯å¤©ä¸­å›½æ—¶é—´20ç‚¹(UTC 12ç‚¹)æ‰§è¡Œ")
    parser.add_argument('--run-once', action='store_true',
                       help="ç«‹å³æ‰§è¡Œä¸€æ¬¡æµ‹è¯•ä»»åŠ¡")
    parser.add_argument('--version', action='version', version='SubsCheck-Ubuntu v1.0')
    
    args = parser.parse_args()
    
    try:
        # è®¾ç½®debugæ¨¡å¼
        debug_logger = setup_logger(debug_mode=args.debug, debug_dir=args.debug_dir)
        log = get_logger()
        
        if args.debug:
            log.info("ğŸ› Debugæ¨¡å¼å·²å¯ç”¨")
            
            # è®°å½•ç³»ç»Ÿä¿¡æ¯
            import platform
            import sys
            debug_info = {
                'platform': platform.platform(),
                'python_version': sys.version,
                'command_args': vars(args),
                'timestamp': datetime.now().isoformat()
            }
            debug_logger.save_debug_info(debug_info, 'system_info.json')
            
            # æµ‹è¯•PowerShellå‘½ä»¤
            log_pwsh_command('Get-Host | Select-Object Version')
        
        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
        if args.max_nodes:
            config['test_settings']['max_test_nodes'] = args.max_nodes
        
        # æ ¹æ®å‚æ•°å†³å®šè¿è¡Œæ¨¡å¼
        if args.scheduler:
            # å®šæ—¶ä»»åŠ¡æ¨¡å¼
            log.info("ğŸ•‘ å¯åŠ¨å®šæ—¶ä»»åŠ¡æ¨¡å¼")
            start_scheduler(config)
        elif args.run_once:
            # ç«‹å³æ‰§è¡Œä¸€æ¬¡
            log.info("ğŸš€ ç«‹å³æ‰§è¡Œä¸€æ¬¡æµ‹è¯•")
            await run_speed_test(args.config, args.subscription, args.max_nodes, args.debug)
        else:
            # é»˜è®¤æ¨¡å¼ï¼šç›´æ¥è¿è¡Œ
            checker = SubsCheckUbuntu(config)
            await checker.run(args.subscription)
        
    except KeyboardInterrupt:
        log = get_logger()
        log.info("ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        log = get_logger()
        log.error(f"ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())