#!/usr/bin/env python3
"""
SubsCheck-Singbox v3.0 - Python+Goæ··åˆæ¶æ§‹
åŸºæ–¼Goèªè¨€æ ¸å¿ƒçš„é«˜æ€§èƒ½ä»£ç†ç¯€é»æ¸¬é€Ÿå·¥å…·
"""

import asyncio
import json
import os
import subprocess
import sys
import time
import argparse
import re
import threading
import codecs
import signal
from pathlib import Path
from typing import Dict, List, Any, Optional
import yaml
import logging
from datetime import datetime

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# é¡è‰²å’Œæ¨£å¼å®šç¾©
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# é€²åº¦æ¢é¡¯ç¤º
class ProgressBar:
    def __init__(self, total: int, width: int = 50):
        self.total = total
        self.width = width
        self.current = 0
        self.available = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
        self.active = True
        
    def update(self, current: int, available: int):
        with self.lock:
            self.current = current
            self.available = available
            
    def increment(self, available: bool = False):
        with self.lock:
            self.current += 1
            if available:
                self.available += 1
                
    def display(self):
        if not self.active:
            return
            
        percent = self.current / self.total if self.total > 0 else 0
        filled_width = int(self.width * percent)
        bar = 'â–ˆ' * filled_width + 'â–‘' * (self.width - filled_width)
        
        elapsed = time.time() - self.start_time
        if self.current > 0:
            eta = (elapsed / self.current) * (self.total - self.current)
        else:
            eta = 0
            
        # è¨ˆç®—æˆåŠŸç‡
        success_rate = (self.available / self.current * 100) if self.current > 0 else 0
        
        print(f'\r{Colors.OKBLUE}ğŸ”„ é€²åº¦: {Colors.BOLD}{bar}{Colors.ENDC} {percent:.1%} '
              f'({self.current}/{self.total}) '
              f'{Colors.OKGREEN}âœ“{self.available}{Colors.ENDC} '
              f'{Colors.WARNING}â±ï¸ {elapsed:.1f}s{Colors.ENDC} '
              f'{Colors.OKBLUE}â³ ETA: {eta:.1f}s{Colors.ENDC} '
              f'{Colors.OKGREEN}æˆåŠŸç‡: {success_rate:.1f}%{Colors.ENDC}', 
              end='', flush=True)
              
    def finish(self):
        self.active = False
        print()  # æ›è¡Œ

class GoSubsChecker:
    """Goæ ¸å¿ƒæ¸¬é€Ÿå™¨çš„PythonåŒ…è£å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = config_path
        self.go_executable = None
        self.config = self._load_config()
        
    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®æ–‡ä»¶å¤±æ•—: {e}")
            return {}
    
    def _find_go_executable(self) -> Optional[str]:
        """æŸ¥æ‰¾Goå¯åŸ·è¡Œæ–‡ä»¶"""
        possible_names = [
            "subscheck.exe",
            "subscheck",
            "subs-check.exe", 
            "subs-check"
        ]
        
        # é¦–å…ˆæª¢æŸ¥ç•¶å‰ç›®éŒ„
        for name in possible_names:
            if Path(name).exists():
                return str(Path(name).absolute())
        
        # æª¢æŸ¥æ§‹å»ºç›®éŒ„
        build_dir = Path("build")
        if build_dir.exists():
            for name in possible_names:
                exe_path = build_dir / name
                if exe_path.exists():
                    return str(exe_path.absolute())
        
        return None
    
    async def compile_go_if_needed(self) -> bool:
        """å¦‚æœéœ€è¦ï¼Œç·¨è­¯Goç¨‹åº"""
        self.go_executable = self._find_go_executable()
        
        if self.go_executable and Path(self.go_executable).exists():
            logger.info(f"âœ… æ‰¾åˆ°Goå¯åŸ·è¡Œæ–‡ä»¶: {self.go_executable}")
            return True
        
        logger.info("ğŸ”¨ Goå¯åŸ·è¡Œæ–‡ä»¶ä¸å­˜åœ¨ï¼Œé–‹å§‹ç·¨è­¯...")
        
        # æª¢æŸ¥Goç’°å¢ƒ
        try:
            result = subprocess.run(["go", "version"], capture_output=True, text=True, timeout=10)
            if result.returncode != 0:
                logger.error("âŒ Goç’°å¢ƒæœªæ‰¾åˆ°ï¼Œè«‹å®‰è£Goèªè¨€")
                return False
            logger.info(f"âœ… Goç’°å¢ƒ: {result.stdout.strip()}")
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥Goç’°å¢ƒå¤±æ•—: {e}")
            return False
        
        # ç·¨è­¯Goç¨‹åº
        try:
            build_dir = Path("build")
            build_dir.mkdir(exist_ok=True)
            
            executable_name = "subscheck.exe" if os.name == 'nt' else "subscheck"
            output_path = build_dir / executable_name
            
            compile_cmd = [
                "go", "build", 
                "-ldflags", "-s -w",
                "-o", str(output_path),
                "."
            ]
            
            logger.info("ğŸ”¨ ç·¨è­¯ä¸­...")
            result = subprocess.run(
                compile_cmd, 
                capture_output=True, 
                text=True, 
                timeout=120
            )
            
            if result.returncode != 0:
                logger.error(f"âŒ ç·¨è­¯å¤±æ•—: {result.stderr}")
                return False
            
            self.go_executable = str(output_path)
            logger.info(f"âœ… ç·¨è­¯æˆåŠŸ: {self.go_executable}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç·¨è­¯éç¨‹å‡ºéŒ¯: {e}")
            return False
    
    async def parse_subscriptions(self, subscription_file: str = "subscription.txt") -> List[str]:
        """è§£æè¨‚é–±æ–‡ä»¶ï¼Œç²å–æ‰€æœ‰è¨‚é–±éˆæ¥"""
        subscription_urls = []
        
        # å¾subscription.txtè®€å–
        if Path(subscription_file).exists():
            with open(subscription_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and line.startswith('http'):
                        subscription_urls.append(line)
        
        # å¾config.yamlçš„sub-urlsè®€å–
        config_urls = self.config.get('sub-urls', [])
        subscription_urls.extend(config_urls)
        
        # å»é‡
        subscription_urls = list(set(subscription_urls))
        logger.info(f"ğŸ“‹ è§£æåˆ° {len(subscription_urls)} å€‹è¨‚é–±éˆæ¥")
        
        return subscription_urls

    async def _fetch_and_parse_single(self, url: str) -> List[str]:
        try:
            content = await self.fetch_subscription_content(url)
            if not content:
                return []
            nodes = await self.parse_nodes_from_content(content)
            return nodes
        except Exception:
            return []

    async def collect_nodes_concurrently(self, urls: List[str], max_nodes: int, concurrency: int = 3) -> List[str]:
        """ä¸¦ç™¼ç²å–ä¸¦è§£æå¤šå€‹è¨‚é–±ï¼Œé”åˆ°ä¸Šé™å³åœæ­¢"""
        semaphore = asyncio.Semaphore(concurrency)
        collected: List[str] = []
        lock = asyncio.Lock()

        async def worker(u: str):
            nonlocal collected
            async with semaphore:
                nodes = await self._fetch_and_parse_single(u)
                async with lock:
                    if nodes:
                        collected.extend(nodes)
                        try:
                            from urllib.parse import urlparse
                            host = urlparse(u).netloc or u
                        except Exception:
                            host = u
                        print(f"{Colors.OKGREEN}âœ… ä¾†æº[{host}] è§£æåˆ° {len(nodes)} å€‹ç¯€é»{Colors.ENDC}")
                    else:
                        try:
                            from urllib.parse import urlparse
                            host = urlparse(u).netloc or u
                        except Exception:
                            host = u
                        logger.warning(f"ä¾†æº[{host}] æœªè§£æåˆ°æœ‰æ•ˆç¯€é»")
        
        tasks = []
        for i, u in enumerate(urls, 1):
            print(f"{Colors.OKBLUE}ğŸ“¡ ç²å–è¨‚é–± {i}/{len(urls)}: {u[:60]}...{Colors.ENDC}")
            tasks.append(asyncio.create_task(worker(u)))
        
        # ç­‰å¾…ä»»å‹™å®Œæˆï¼ŒåŒæ™‚æª¢æŸ¥æ˜¯å¦é”åˆ°ä¸Šé™
        for t in asyncio.as_completed(tasks):
            await t
            async with lock:
                if len(collected) >= max_nodes:
                    break
        
        # å–æ¶ˆå‰©é¤˜ä»»å‹™
        for t in tasks:
            if not t.done():
                t.cancel()
        
        return collected[:max_nodes]
    
    async def fetch_subscription_content(self, url: str) -> str:
        """ç²å–è¨‚é–±å…§å®¹"""
        import aiohttp
        import random
        import ssl
        from urllib.parse import urlparse
        
        max_retries = 5  # å¢åŠ é‡è©¦æ¬¡æ•°
        retry_delay = 1.0  # åˆå§‹é‡è©¦å»¶é²æ™‚é–“
        
        # å¸¸è¦‹ç€è¦½å™¨çš„User-Agentåˆ—è¡¨
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',
            'SubCheck-Singbox/3.0'
        ]
        
        # è§£æåŸŸåç”¨æ–¼SNI
        parsed = urlparse(url)
        ssl_ctx = ssl.create_default_context()
        
        # ä½¿ç”¨è¿æ¥æ± ä¼˜åŒ–
        connector = aiohttp.TCPConnector(
            limit_per_host=5,
            ssl=ssl_ctx
        )
        
        # æ‡‰ç”¨ GitHub ä»£ç†é¡åƒï¼ˆå¦‚é…ç½®æä¾›ï¼‰ï¼ŒåŠ é€Ÿå¤§é™¸ç’°å¢ƒè¨ªå•
        gh_proxy = (self.config.get('github-proxy') or self.config.get('github_proxy') or '').strip()
        request_url = url
        if gh_proxy and url.startswith(('https://raw.githubusercontent.com', 'https://github.com', 'https://gist.github.com', 'https://api.github.com')):
            # å¸¸è¦‹é¡åƒå¯«æ³•ï¼š'https://ghproxy.com/' + åŸå§‹URL
            request_url = gh_proxy.rstrip('/') + '/' + url

        # æ”¯æŒåœ¨å¤§é™¸ç’°å¢ƒä¸‹é€šéæœ¬åœ°/ä¸Šæ¸¸ä»£ç†æ‹‰å–è¨‚é–±
        http_proxy = (self.config.get('proxy') or self.config.get('http_proxy') or '').strip() or None

        async with aiohttp.ClientSession(connector=connector, trust_env=False) as session:
            for attempt in range(max_retries + 1):
                try:
                    # ä½¿ç”¨æ›´çµæ´»çš„è¶…æ—¶è®¾ç½®
                    timeout = aiohttp.ClientTimeout(
                        total=60,  # å¢åŠ æ€»è¶…æ—¶æ—¶é—´
                        connect=30,  # å¢åŠ è¿æ¥è¶…æ—¶æ—¶é—´
                        sock_read=45,  # å¢åŠ å¥—æ¥å­—è¯»å–è¶…æ—¶
                        sock_connect=20  # å¢åŠ å¥—æ¥å­—è¿æ¥è¶…æ—¶
                    )
                    
                    # éš¨æ©Ÿé€‰æ‹©User-Agent
                    headers = {
                        'User-Agent': random.choice(user_agents),
                        'Accept': '*/*',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Connection': 'keep-alive',
                        'Cache-Control': 'no-cache'
                    }
                    
                    async with session.get(request_url, headers=headers, timeout=timeout, proxy=http_proxy) as response:
                        if response.status == 200:
                            content = await response.text()
                            logger.debug(f"âœ… ç²å–è¨‚é–±æˆåŠŸ: {request_url[:50]}... (å˜—è©¦æ¬¡æ•¸: {attempt + 1})")
                            
                            # å…³é—­è¿æ¥æ± ä¸­çš„è¿æ¥ä»¥é¿å…èµ„æºæ³„æ¼
                            await session.connector.close()
                            return content
                        elif response.status == 301 or response.status == 302:
                            # å¤„ç†é‡å®šå‘
                            redirect_url = response.headers.get('Location')
                            if redirect_url:
                                logger.info(f"ğŸ”„ è¨‚é–±æºé‡å®šå‘åˆ°: {redirect_url} (å˜—è©¦æ¬¡æ•¸: {attempt + 1})")
                                request_url = redirect_url  # æ›´æ–°URLä»¥è¿›è¡Œé‡è¯•
                                continue
                        else:
                            logger.warning(f"âš ï¸ è¨‚é–±éŸ¿æ‡‰éŒ¯èª¤ {response.status}: {request_url[:50]}... (å˜—è©¦æ¬¡æ•¸: {attempt + 1})")
                            
                except asyncio.TimeoutError:
                    logger.warning(f"â° è¨‚é–±æºè¨ªå•è¶…æ™‚ (ç¬¬{attempt + 1}æ¬¡å˜—è©¦): {request_url} (é€£æ¥è¶…æ™‚)")
                except aiohttp.ClientResponseError as e:
                    logger.warning(f"ğŸŒ è¨‚é–±æºéŸ¿æ‡‰éŒ¯èª¤ (ç¬¬{attempt + 1}æ¬¡å˜—è©¦): {request_url} - {e}")
                except aiohttp.ClientConnectionError as e:
                    logger.warning(f"ğŸ”Œ è¨‚é–±æºé€£æ¥éŒ¯èª¤ (ç¬¬{attempt + 1}æ¬¡å˜—è©¦): {request_url} - {e}")
                except aiohttp.ClientError as e:
                    logger.warning(f"ğŸŒ è¨‚é–±æºç¶²çµ¡éŒ¯èª¤ (ç¬¬{attempt + 1}æ¬¡å˜—è©¦): {request_url} - {e}")
                except Exception as e:
                    logger.warning(f"âŒ è¨‚é–±æºè¨ªå•å¤±æ•— (ç¬¬{attempt + 1}æ¬¡å˜—è©¦): {request_url} - {e}")
                
                if attempt < max_retries:
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 2  # æŒ‡æ•°é€€é¿ç­–ç•¥
                    # éš¨æœºæŠ–åŠ¨ï¼Œé¿å…æ‰€æœ‰è¯·æ±‚åŒæ­¥
                    retry_delay += random.uniform(0, retry_delay)
        
        logger.error(f"âŒ è¨‚é–±æº {request_url} åœ¨ {max_retries + 1} æ¬¡å˜—è©¦å¾Œä»ç„¶ç„¡æ³•è¨ªå•")
        # å…³é—­è¿æ¥æ± ä¸­çš„è¿æ¥ä»¥é¿å…èµ„æºæ³„æ¼
        await session.connector.close()
        return ""
    
    async def parse_nodes_from_content(self, content: str) -> List[str]:
        """å¾è¨‚é–±å…§å®¹è§£æç¯€é»ï¼ˆå¤šç­–ç•¥è§£ç¢¼ï¼Œé¸æ“‡æœ€å„ªçµæœï¼‰"""
        import base64
        import re
        import gzip
        import zlib

        def extract_nodes_from_text(text: str) -> List[str]:
            nodes_local: List[str] = []
            for raw_line in text.splitlines():
                line = raw_line.strip()
                if not line:
                    continue
                if any(line.startswith(proto) for proto in ['ss://', 'vmess://', 'vless://', 'trojan://', 'hysteria://', 'tuic://']):
                    nodes_local.append(line)
            return nodes_local

        def try_decoders(raw_bytes: bytes) -> List[str]:
            candidates: List[str] = []
            # 1) åŸå§‹æ–‡æœ¬
            try:
                candidates.append(raw_bytes.decode('utf-8', errors='ignore'))
            except Exception:
                candidates.append(str(content))
            # 2) Base64ï¼ˆå¯¬é¬†ï¼Œå¿½ç•¥ç©ºç™½ï¼‰
            try:
                b64_clean = re.sub(rb"\s+", b"", raw_bytes)
                candidates.append(base64.b64decode(b64_clean, validate=False).decode('utf-8', errors='ignore'))
            except Exception:
                pass
            # 3) gzip
            try:
                candidates.append(gzip.decompress(raw_bytes).decode('utf-8', errors='ignore'))
            except Exception:
                pass
            # 4) zlib
            try:
                candidates.append(zlib.decompress(raw_bytes).decode('utf-8', errors='ignore'))
            except Exception:
                pass
            return candidates

        raw_bytes = content if isinstance(content, (bytes, bytearray)) else str(content).encode('utf-8', errors='ignore')
        texts = try_decoders(raw_bytes)

        # é¸æ“‡åŒ…å«æœ€å¤šç¯€é»URIçš„æ–‡æœ¬ä½œç‚ºæœ€å„ªè§£ç¢¼çµæœ
        best_text: str = ''
        best_nodes: List[str] = []
        for t in texts:
            nodes_candidate = extract_nodes_from_text(t)
            if len(nodes_candidate) > len(best_nodes):
                best_nodes = nodes_candidate
                best_text = t

        # è‹¥æ‰€æœ‰è§£ç¢¼éƒ½æœªæå–åˆ°ç¯€é»ï¼Œé€€å›æœ€å¯èƒ½çš„æ–‡æœ¬ï¼ˆåŸå§‹æ–‡æœ¬ï¼‰
        if not best_nodes:
            best_text = texts[0] if texts else (content if isinstance(content, str) else '')

        nodes: List[str] = []
        for raw_line in best_text.splitlines():
            line = raw_line.strip()
            if not line:
                continue
            if any(line.startswith(proto) for proto in ['ss://', 'vmess://', 'vless://', 'trojan://', 'hysteria://', 'tuic://']):
                nodes.append(line)
            elif line.startswith('http') and ('subscribe' in line or 'sub' in line):
                # åµŒå¥—è¨‚é–±ï¼Œéæ­¸ç²å–
                nested_content = await self.fetch_subscription_content(line)
                if nested_content:
                    nested_nodes = await self.parse_nodes_from_content(nested_content)
                    nodes.extend(nested_nodes)

        return nodes
    
    async def run_speed_test(self, subscription_file: str = "subscription.txt") -> Dict[str, Any]:
        """Pythonè§£æè¨‚é–± + Goæ ¸å¿ƒæ¸¬é€Ÿçš„æ··åˆæ–¹æ¡ˆ"""
        if not self.go_executable:
            logger.error(f"{Colors.FAIL}âŒ Goå¯åŸ·è¡Œæ–‡ä»¶æœªæ‰¾åˆ°{Colors.ENDC}")
            return {"success": False, "error": "Go executable not found"}

        temp_dir = Path("temp_subscheck")
        temp_dir.mkdir(exist_ok=True)
        
        httpd = None
        progress_bar = None
        temp_config_file = Path("temp_config.yaml")
        process = None

        try:
            print(f"\n{Colors.OKGREEN}ğŸš€ é–‹å§‹Python+Goæ··åˆæ¸¬é€Ÿ...{Colors.ENDC}")
            print(f"{Colors.OKBLUE}ğŸ“ é…ç½®æ–‡ä»¶: {self.config_path}{Colors.ENDC}")
            print(f"{Colors.OKBLUE}ğŸ“„ è¨‚é–±æ–‡ä»¶: {subscription_file}{Colors.ENDC}")

            # Phase 1: Pythonè§£æè¨‚é–±
            print(f"\n{Colors.WARNING}ğŸ Phase 1: Pythonè§£æè¨‚é–±...{Colors.ENDC}")
            subscription_urls = await self.parse_subscriptions(subscription_file)

            if not subscription_urls:
                print(f"{Colors.FAIL}âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¨‚é–±éˆæ¥{Colors.ENDC}")
                return {"success": False, "error": "No valid subscription URLs found"}

            all_nodes: List[str] = []
            max_test_nodes = 100
            # ä¸¦ç™¼æŠ“å–èˆ‡è§£æï¼ŒåŠ é€Ÿæ…¢æº
            all_nodes = await self.collect_nodes_concurrently(subscription_urls, max_test_nodes, concurrency=min(4, len(subscription_urls)))

            unique_nodes = list(set(all_nodes))
            print(f"{Colors.OKBLUE}ğŸ“Š ç¸½ç¯€é»æ•¸: {len(all_nodes)}, å»é‡å¾Œ: {len(unique_nodes)}{Colors.ENDC}")

            if not unique_nodes:
                print(f"{Colors.FAIL}âŒ æ²’æœ‰è§£æåˆ°æœ‰æ•ˆç¯€é»{Colors.ENDC}")
                return {"success": False, "error": "No valid nodes found"}
            if len(unique_nodes) > max_test_nodes:
                unique_nodes = unique_nodes[:max_test_nodes]
                print(f"{Colors.WARNING}âš¡ é™åˆ¶æ¸¬è©¦ç¯€é»æ•¸é‡ç‚º {max_test_nodes}{Colors.ENDC}")

            # Phase 2: Goæ ¸å¿ƒæ¸¬é€Ÿ
            print(f"\n{Colors.WARNING}âš¡ Phase 2: Goæ ¸å¿ƒæ¸¬é€Ÿ...{Colors.ENDC}")

            from http.server import HTTPServer, BaseHTTPRequestHandler

            test_port = 8299
            nodes_content = '\n'.join(unique_nodes)

            class NodeHandler(BaseHTTPRequestHandler):
                def do_GET(self):
                    if self.path == '/nodes':
                        self.send_response(200)
                        self.send_header('Content-type', 'text/plain; charset=utf-8')
                        self.end_headers()
                        self.wfile.write(nodes_content.encode('utf-8'))
                    else:
                        self.send_response(404)
                        self.end_headers()
                
                def log_message(self, format, *args):
                    pass

            httpd = HTTPServer(('127.0.0.1', test_port), NodeHandler)
            server_thread = threading.Thread(target=httpd.serve_forever, daemon=True)
            server_thread.start()
            print(f"{Colors.OKGREEN}ğŸŒ è‡¨æ™‚HTTPæœå‹™å™¨å•Ÿå‹•: http://127.0.0.1:{test_port}/nodes{Colors.ENDC}")

            temp_config = self.config.copy()
            temp_config['sub-urls'] = [f"http://127.0.0.1:{test_port}/nodes"]
            # å¼ºåˆ¶è®¾ç½®cronè¡¨è¾¾å¼ä¸ºç©ºï¼Œç¡®ä¿Goç¨‹åºç«‹å³æ‰§è¡Œè€Œä¸æ˜¯ç­‰å¾…å®šæ—¶ä»»åŠ¡
            temp_config['cron-expression'] = ""
            # å¼ºåˆ¶ç¦ç”¨Goä¾§HTTPæœåŠ¡å™¨ï¼Œé¿å…å…¶å¸¸é©»å¯¼è‡´Pythonç­‰å¾…é€€å‡º
            temp_config['listen-port'] = ""
            
            with open(temp_config_file, 'w', encoding='utf-8') as f:
                import yaml
                yaml.dump(temp_config, f, default_flow_style=False, allow_unicode=True)

            cmd = [self.go_executable, "-f", str(temp_config_file)]
            start_time = time.time()
            print(f"{Colors.OKBLUE}ğŸ”„ å•Ÿå‹•Goæ¸¬é€Ÿç¨‹åº...{Colors.ENDC}")

            progress_bar = ProgressBar(len(unique_nodes))
            progress_thread = threading.Thread(target=self._show_progress, args=(progress_bar,))
            progress_thread.daemon = True
            progress_thread.start()

            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=Path.cwd()
            )

            # å¯¦æ™‚è®€å–Goè¼¸å‡ºï¼Œæ ¹æ“šé€²åº¦è¡Œæ›´æ–°é€²åº¦æ¢ï¼›æª¢æ¸¬åˆ°å®Œæˆå¾Œç«‹å³çµæŸGoé€²ç¨‹
            stdout_lines: List[str] = []
            stderr_lines: List[str] = []
            timeout_occurred = False

            completion_event = asyncio.Event()

            async def _read_stream(stream: asyncio.StreamReader, is_stdout: bool):
                nonlocal stdout_lines, stderr_lines
                buffer = ''
                while True:
                    try:
                        chunk = await stream.read(1024)
                    except Exception:
                        break
                    if not chunk:
                        # flush remaining buffer
                        if buffer:
                            text = buffer
                            if is_stdout:
                                stdout_lines.append(text)
                            else:
                                stderr_lines.append(text)
                            # parse once more
                            for seg in re.split(r"[\r\n]", text):
                                if not seg:
                                    continue
                                try:
                                    # æ”¯æŒç°¡é«”/ç¹é«”çš„ã€è¿›åº¦/é€²åº¦ã€é—œéµè©
                                    m = re.search(r"[è¿›é€²]åº¦:\s*\[[^\]]*\]\s*(\d+\.\d+)%\s*\((\d+)/(\d+)\)\s*å¯ç”¨:\s*(\d+)", seg)
                                    if m:
                                        _, cur, total, available = m.groups()
                                        progress_bar.update(int(cur), int(available))
                                        if int(total) > 0 and int(cur) >= int(total):
                                            completion_event.set()
                                    if ('æ£€æµ‹å®Œæˆ' in seg) or ('æª¢æ¸¬å®Œæˆ' in seg):
                                        completion_event.set()
                                    if 'å¯ç”¨èŠ‚ç‚¹æ•°é‡' in seg:
                                        completion_event.set()
                                except Exception:
                                    pass
                        break
                    text = chunk.decode('utf-8', errors='ignore')
                    buffer += text
                    # split by CR or LF to form segments
                    parts = re.split(r"([\r\n])", buffer)
                    # reassemble complete segments (ending with a delimiter), keep tail
                    assembled = []
                    tail = ''
                    for i in range(0, len(parts)-1, 2):
                        seg = parts[i]
                        delim = parts[i+1]
                        if delim in ('\r', '\n'):
                            assembled.append(seg)
                        else:
                            tail += seg + delim
                    if len(parts) % 2 == 1:
                        tail += parts[-1]
                    buffer = tail
                    for seg in assembled:
                        if not seg:
                            continue
                        if is_stdout:
                            stdout_lines.append(seg + '\n')
                        else:
                            stderr_lines.append(seg + '\n')
                        try:
                            # æ”¯æŒç°¡é«”/ç¹é«”çš„ã€è¿›åº¦/é€²åº¦ã€é—œéµè©
                            m = re.search(r"[è¿›é€²]åº¦:\s*\[[^\]]*\]\s*(\d+\.\d+)%\s*\((\d+)/(\d+)\)\s*å¯ç”¨:\s*(\d+)", seg)
                            if m:
                                _, cur, total, available = m.groups()
                                progress_bar.update(int(cur), int(available))
                                if int(total) > 0 and int(cur) >= int(total):
                                    completion_event.set()
                            if ('æ£€æµ‹å®Œæˆ' in seg) or ('æª¢æ¸¬å®Œæˆ' in seg):
                                completion_event.set()
                            if 'å¯ç”¨èŠ‚ç‚¹æ•°é‡' in seg:
                                completion_event.set()
                        except Exception:
                            pass

            reader_tasks = [
                asyncio.create_task(_read_stream(process.stdout, True)),
                asyncio.create_task(_read_stream(process.stderr, False))
            ]

            # ä¼°ç®—æœ€å¤§ç­‰å¾…æ™‚é–“ï¼Œäº¦ä½œç‚ºä¿éšªè¶…æ™‚
            wait_time = min(120 + len(unique_nodes) // 5, 600)
            print(f"{Colors.WARNING}â³ ç­‰å¾…Goç¨‹åºå®Œæˆæ¸¬é€Ÿ (æœ€é•· {wait_time} ç§’)...{Colors.ENDC}")

            try:
                # ç­‰å¾…å®Œæˆäº‹ä»¶æˆ–ç¸½è¶…æ™‚
                await asyncio.wait_for(completion_event.wait(), timeout=wait_time)
            except asyncio.TimeoutError:
                timeout_occurred = True
                print(f"{Colors.WARNING}âš ï¸ Goç¨‹åºè¶…æ™‚ï¼Œå¼·åˆ¶çµ‚æ­¢{Colors.ENDC}")
            finally:
                # å˜—è©¦å„ªé›…çµæŸGoé€²ç¨‹
                try:
                    if process.returncode is None:
                        process.terminate()
                        try:
                            await asyncio.wait_for(process.wait(), timeout=3)
                        except asyncio.TimeoutError:
                            process.kill()
                            await process.wait()
                except Exception:
                    pass

                # ç­‰å¾…è®€å–ä»»å‹™çµæŸ
                try:
                    await asyncio.wait_for(asyncio.gather(*reader_tasks, return_exceptions=True), timeout=3)
                except asyncio.TimeoutError:
                    for t in reader_tasks:
                        t.cancel()

            stdout = ''.join(stdout_lines)
            stderr = ''.join(stderr_lines)


            duration = time.time() - start_time
            print(f"{Colors.OKGREEN}âœ… Goæ ¸å¿ƒæ¸¬é€Ÿå®Œæˆ (è€—æ™‚: {duration:.1f}s){Colors.ENDC}")

            results = self._parse_go_output(stdout, stderr)
            
            return {
                "success": True,
                "results": results,
                "total_nodes": len(all_nodes),
                "tested_nodes": len(unique_nodes),
                "duration": duration,
                "stdout": stdout,
                "stderr": stderr,
                "timeout": timeout_occurred
            }

        finally:
            if progress_bar:
                progress_bar.finish()
            if httpd:
                httpd.shutdown()
                httpd.server_close()
            if temp_config_file.exists():
                try:
                    os.remove(temp_config_file)
                except OSError as e:
                    logger.warning(f"ç„¡æ³•åˆªé™¤è‡¨æ™‚é…ç½®æ–‡ä»¶: {e}")
            
            # ç¢ºä¿é€²ç¨‹è¢«å¾¹åº•æ¸…ç†
            if process and process.returncode is None:
                try:
                    process.kill()
                    await process.wait()
                except Exception as e:
                    logger.warning(f"æ¸…ç†Goé€²ç¨‹æ™‚å‡ºéŒ¯: {e}")
    
    def _show_progress(self, progress_bar: ProgressBar):
        """é¡¯ç¤ºé€²åº¦æ¢çš„ç·šç¨‹å‡½æ•¸"""
        while progress_bar.active:
            progress_bar.display()
            time.sleep(0.5)
    
    def _parse_go_output(self, stdout: str, stderr: str) -> Dict[str, Any]:
        """è§£æGoç¨‹åºçš„è¼¸å‡ºï¼Œæå–æ¸¬é€Ÿçµæœ"""
        import re
        
        results = {
            "progress_info": [],
            "test_results": [],
            "statistics": {},
            "successful_nodes": [],
            "failed_nodes": []
        }
        
        if not stdout:
            return results
        
        lines = stdout.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # è§£æé€²åº¦ä¿¡æ¯ï¼ˆæ”¯æŒç°¡é«”/ç¹é«”ã€è¿›åº¦/é€²åº¦ã€ï¼‰
            if (('è¿›åº¦:' in line) or ('é€²åº¦:' in line)) and 'å¯ç”¨:' in line:
                progress_match = re.search(r'[è¿›é€²]åº¦:.*?(\d+\.\d+)%.*?\((\d+)/(\d+)\).*?å¯ç”¨:\s*(\d+)', line)
                if progress_match:
                    percent, current, total, available = progress_match.groups()
                    results["progress_info"].append({
                        "percent": float(percent),
                        "current": int(current),
                        "total": int(total),
                        "available": int(available)
                    })
            
            # è§£æçµ±è¨ˆä¿¡æ¯
            elif 'INFO' in line:
                if 'è·å–èŠ‚ç‚¹æ•°é‡:' in line:
                    match = re.search(r'è·å–èŠ‚ç‚¹æ•°é‡:\s*(\d+)', line)
                    if match:
                        results["statistics"]["total_nodes"] = int(match.group(1))
                elif 'å»é‡åèŠ‚ç‚¹æ•°é‡:' in line:
                    match = re.search(r'å»é‡åèŠ‚ç‚¹æ•°é‡:\s*(\d+)', line)
                    if match:
                        results["statistics"]["unique_nodes"] = int(match.group(1))
                elif 'å¯ç”¨èŠ‚ç‚¹æ•°é‡:' in line:
                    match = re.search(r'å¯ç”¨èŠ‚ç‚¹æ•°é‡:\s*(\d+)', line)
                    if match:
                        results["statistics"]["available_nodes"] = int(match.group(1))
                elif 'æµ‹è¯•æ€»æ¶ˆè€—æµé‡:' in line:
                    match = re.search(r'æµ‹è¯•æ€»æ¶ˆè€—æµé‡:\s*([\d.]+)GB', line)
                    if match:
                        results["statistics"]["total_traffic"] = float(match.group(1))
            
            # è§£æç¯€é»æ¸¬è©¦çµæœ (å‡è¨­Goç¨‹åºæœƒè¼¸å‡ºé¡ä¼¼æ ¼å¼)
            # æˆ‘å€‘éœ€è¦ä¿®æ”¹Goç¨‹åºä¾†è¼¸å‡ºæ›´è©³ç´°çš„ç¯€é»ä¿¡æ¯
            elif 'âœ“' in line or 'âœ—' in line:
                # å˜—è©¦è§£æç¯€é»æ¸¬è©¦çµæœ
                # æ ¼å¼: âœ“ [å”è­°] ç¯€é»å - IP:ç«¯å£ | å»¶é²: XXXms | é€Ÿåº¦: XXX Mbps
                node_match = re.search(r'([âœ“âœ—])\s*\[([^\]]+)\]\s*([^-]+)-\s*([^|]+)\|.*?å»¶é²:\s*(\d+)ms.*?é€Ÿåº¦:\s*([\d.]+)\s*Mbps', line)
                if node_match:
                    status, protocol, name, ip_port, latency, speed = node_match.groups()
                    node_result = {
                        "name": name.strip(),
                        "protocol": protocol.strip(),
                        "ip_port": ip_port.strip(),
                        "latency": int(latency),
                        "speed": float(speed),
                        "success": status == 'âœ“'
                    }
                    
                    if node_result["success"]:
                        results["successful_nodes"].append(node_result)
                    else:
                        results["failed_nodes"].append(node_result)
        
        return results
    
    def display_results(self, result: Dict[str, Any]):
        """é¡¯ç¤ºæ¸¬é€Ÿçµæœ"""
        if not result.get("success"):
            print(f"\n{Colors.FAIL}âŒ æ¸¬é€Ÿå¤±æ•—: {result.get('error', 'Unknown error')}{Colors.ENDC}")
            return
        
        # é¡¯ç¤ºçµæœæ¨™é¡Œ
        print(f"\n{Colors.BOLD}{Colors.HEADER}{'=' * 80}{Colors.ENDC}")
        print(f"{Colors.BOLD}{Colors.HEADER}ğŸ¯ SubsCheck-Singbox v3.0 Python+Goæ··åˆæ¸¬é€Ÿçµæœ{Colors.ENDC}")
        print(f"{Colors.BOLD}{Colors.HEADER}{'=' * 80}{Colors.ENDC}")
        
        # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
        total_nodes = result.get("total_nodes", 0)
        tested_nodes = result.get("tested_nodes", 0)
        duration = result.get("duration", 0)
        
        # å„ªå…ˆä½¿ç”¨Goç«¯å»é‡å¾Œçš„ç¯€é»æ•¸æˆ–é€²åº¦ç¸½æ•¸ï¼Œä»¥é¿å…èˆ‡Pythonå´çµ±è¨ˆä¸ä¸€è‡´
        results = result.get("results", {})
        statistics = results.get("statistics", {})
        progress_info = results.get("progress_info", [])
        tested_nodes_display = tested_nodes
        if isinstance(statistics.get("unique_nodes"), int) and statistics.get("unique_nodes") > 0:
            tested_nodes_display = statistics.get("unique_nodes")
        elif progress_info:
            tested_nodes_display = progress_info[-1].get("total", tested_nodes)

        print(f"{Colors.OKBLUE}ğŸ“Š ç¯€é»çµ±è¨ˆ:{Colors.ENDC}")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} Pythonè§£æç¯€é»: {Colors.BOLD}{total_nodes:,}{Colors.ENDC}")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å¯¦éš›æ¸¬è©¦ç¯€é»: {Colors.BOLD}{tested_nodes_display:,}{Colors.ENDC}")
        
        # è§£æä¸¦é¡¯ç¤ºGoç¨‹åºçš„çµæœ
        statistics = results.get("statistics", {})
        successful_nodes = results.get("successful_nodes", [])
        failed_nodes = results.get("failed_nodes", [])
        
        # å˜—è©¦å¾stderrç²å–æ›´å¤šçµ±è¨ˆä¿¡æ¯
        available_count = 0
        total_traffic = 0.0
        
        if result.get("stderr"):
            stderr_lines = result["stderr"].split('\n')
            for line in stderr_lines:
                if 'INFO' in line:
                    if 'å¯ç”¨èŠ‚ç‚¹æ•°é‡:' in line:
                        match = re.search(r'å¯ç”¨èŠ‚ç‚¹æ•°é‡:\s*(\d+)', line)
                        if match:
                            available_count = int(match.group(1))
                    elif 'æµ‹è¯•æ€»æ¶ˆè€—æµé‡:' in line:
                        match = re.search(r'æµ‹è¯•æ€»æ¶ˆè€—æµé‡:\s*([\d.]+)GB', line)
                        if match:
                            total_traffic = float(match.group(1))
        
        # å¦‚æœæ²’æœ‰å¾stderrç²å–åˆ°ï¼Œä½¿ç”¨ä¹‹å‰è§£æçš„æ•¸æ“š
        if available_count == 0 and "available_nodes" in statistics:
            available_count = statistics["available_nodes"]
        if total_traffic == 0.0 and "total_traffic" in statistics:
            total_traffic = statistics["total_traffic"]
        
        # é¡¯ç¤ºGoæ ¸å¿ƒæ¸¬é€Ÿçµ±è¨ˆ
        print(f"\n{Colors.WARNING}âš¡ Goæ ¸å¿ƒæ¸¬é€Ÿçµ±è¨ˆ:{Colors.ENDC}")
        if "total_nodes" in statistics:
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} Goæ¥æ”¶ç¯€é»: {Colors.BOLD}{statistics['total_nodes']}{Colors.ENDC}")
        if "unique_nodes" in statistics:
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å»é‡å¾Œç¯€é»: {Colors.BOLD}{statistics['unique_nodes']}{Colors.ENDC}")
        if available_count > 0:
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å¯ç”¨ç¯€é»: {Colors.BOLD}{Colors.OKGREEN}{available_count}{Colors.ENDC}")
        if total_traffic > 0:
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} æ¶ˆè€—æµé‡: {Colors.BOLD}{total_traffic:.3f} GB{Colors.ENDC}")
        
        # å¦‚æœæ²’æœ‰è§£æåˆ°è©³ç´°ç¯€é»ä¿¡æ¯ï¼Œé¡¯ç¤ºåŸå§‹Goè¼¸å‡ºçš„çµ±è¨ˆ
        if not successful_nodes and not failed_nodes and result.get("stdout"):
            print(f"\n{Colors.OKBLUE}ğŸ“„ Goç¨‹åºåŸå§‹è¼¸å‡ºæ‘˜è¦:{Colors.ENDC}")
            stdout_lines = result["stdout"].split('\n')
            for line in stdout_lines[-20:]:  # é¡¯ç¤ºæœ€å¾Œ20è¡Œ
                if 'INFO' in line and any(keyword in line for keyword in ['èŠ‚ç‚¹æ•°é‡', 'å¯ç”¨èŠ‚ç‚¹', 'æ¶ˆè€—æµé‡', 'æ£€æµ‹å®Œæˆ']):
                    print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} {line.split('INFO')[-1].strip()}")
        
        # é¡¯ç¤ºæˆåŠŸçš„ç¯€é»è©³æƒ…
        if successful_nodes:
            print(f"\n{Colors.OKGREEN}âœ… æˆåŠŸç¯€é»è©³æƒ… ({len(successful_nodes)}å€‹):{Colors.ENDC}")
            print(f"{Colors.OKBLUE}{'-' * 80}{Colors.ENDC}")
            for i, node in enumerate(successful_nodes[:10], 1):  # åªé¡¯ç¤ºå‰10å€‹
                protocol_emoji = {
                    'ss': 'ğŸ”', 'vmess': 'ğŸš€', 'vless': 'âš¡', 
                    'trojan': 'ğŸ›ï¸', 'hysteria': 'ğŸ’¨', 'tuic': 'ğŸ”¥'
                }.get(node.get('protocol', '').lower(), 'ğŸ“¡')
                
                print(f"{Colors.BOLD}{i:2d}.{Colors.ENDC} {protocol_emoji} [{Colors.OKBLUE}{node.get('protocol', 'Unknown')}{Colors.ENDC}] {Colors.BOLD}{node.get('name', 'Unnamed')}{Colors.ENDC}")
                print(f"    ğŸ“ {node.get('ip_port', 'Unknown IP')}")
                print(f"    â±ï¸  å»¶é²: {Colors.WARNING}{node.get('latency', 0)}ms{Colors.ENDC} | ğŸš€ é€Ÿåº¦: {Colors.OKGREEN}{node.get('speed', 0):.2f} Mbps{Colors.ENDC}")
                if i < len(successful_nodes) and i < 10:
                    print()
            
            if len(successful_nodes) > 10:
                print(f"    {Colors.WARNING}... é‚„æœ‰ {len(successful_nodes) - 10} å€‹æˆåŠŸç¯€é»{Colors.ENDC}")
        
        # é¡¯ç¤ºå¤±æ•—ç¯€é»çµ±è¨ˆ
        if failed_nodes:
            print(f"\n{Colors.FAIL}âŒ å¤±æ•—ç¯€é»: {len(failed_nodes)}å€‹{Colors.ENDC}")
            
            # æŒ‰å”è­°åˆ†çµ„çµ±è¨ˆå¤±æ•—ç¯€é»
            failed_by_protocol = {}
            for node in failed_nodes:
                protocol = node.get('protocol', 'Unknown')
                failed_by_protocol[protocol] = failed_by_protocol.get(protocol, 0) + 1
            
            for protocol, count in failed_by_protocol.items():
                print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} {protocol}: {count}å€‹")
        
        # é¡¯ç¤ºé€²åº¦ä¿¡æ¯ï¼ˆæœ€å¾Œä¸€å€‹é€²åº¦ï¼‰
        if progress_info:
            last_progress = progress_info[-1]
            print(f"\n{Colors.OKBLUE}ğŸ“ˆ æ¸¬é€Ÿé€²åº¦:{Colors.ENDC}")
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å®Œæˆåº¦: {Colors.BOLD}{last_progress['percent']:.1f}%{Colors.ENDC}")
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å·²æ¸¬è©¦: {Colors.BOLD}{last_progress['current']}/{last_progress['total']}{Colors.ENDC}")
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å¯¦æ™‚å¯ç”¨: {Colors.BOLD}{Colors.OKGREEN}{last_progress['available']}{Colors.ENDC}")
        
        print(f"\n{Colors.WARNING}â±ï¸  åŸ·è¡Œæ™‚é–“:{Colors.ENDC}")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} ç¸½è€—æ™‚: {Colors.BOLD}{duration:.1f} ç§’{Colors.ENDC}")
        if tested_nodes > 0:
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å¹³å‡æ¯ç¯€é»: {Colors.BOLD}{duration/tested_nodes:.2f} ç§’{Colors.ENDC}")
        
        # è¨ˆç®—æˆåŠŸç‡
        total_tested = len(successful_nodes) + len(failed_nodes)
        if total_tested > 0:
            success_rate = len(successful_nodes) / total_tested * 100
            print(f"\n{Colors.OKBLUE}ğŸ“ˆ æ¸¬è©¦çµæœ:{Colors.ENDC}")
            print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} æˆåŠŸç‡: {Colors.BOLD}{success_rate:.1f}%{Colors.ENDC} ({Colors.OKGREEN}{len(successful_nodes)}{Colors.ENDC}/{total_tested})")
            if successful_nodes:
                avg_speed = sum(node.get('speed', 0) for node in successful_nodes) / len(successful_nodes)
                avg_latency = sum(node.get('latency', 0) for node in successful_nodes) / len(successful_nodes)
                print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å¹³å‡é€Ÿåº¦: {Colors.BOLD}{Colors.OKGREEN}{avg_speed:.2f} Mbps{Colors.ENDC}")
                print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å¹³å‡å»¶é²: {Colors.BOLD}{Colors.WARNING}{avg_latency:.0f}ms{Colors.ENDC}")
        
        print(f"\n{Colors.OKBLUE}ğŸ”§ ç‰ˆæœ¬ä¿¡æ¯:{Colors.ENDC}")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} Pythonæ©‹æ¥: v3.0 (æ™ºèƒ½è¨‚é–±è§£æ)")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} Goæ ¸å¿ƒ: v3.0 (åŸç”Ÿå”è­°æ¸¬é€Ÿ)")
        
        # å¦‚æœæ˜¯è¶…æ™‚çµ‚æ­¢ï¼Œé¡¯ç¤ºæç¤º
        if result.get("timeout"):
            print(f"\n{Colors.WARNING}âš ï¸  æ³¨æ„: Goç¨‹åºå› è¶…æ™‚è¢«çµ‚æ­¢ï¼Œçµæœå¯èƒ½ä¸å®Œæ•´{Colors.ENDC}")
        
        # æ·»åŠ ä½¿ç”¨æç¤º
        print(f"\n{Colors.OKBLUE}ğŸ’¡ ä½¿ç”¨æç¤º:{Colors.ENDC}")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} ç·¨è¼¯ {Colors.BOLD}config.yaml{Colors.ENDC} æ·»åŠ æ‚¨çš„è¨‚é–±éˆæ¥")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} å‰µå»º {Colors.BOLD}.env{Colors.ENDC} æ–‡ä»¶é…ç½® GitHub Gist æˆ– WebDAV")
        print(f"   {Colors.OKGREEN}â””â”€{Colors.ENDC} ä½¿ç”¨ {Colors.BOLD}uv run main.py --help{Colors.ENDC} æŸ¥çœ‹æ›´å¤šé¸é …")
        
        print(f"{Colors.BOLD}{Colors.HEADER}{'=' * 80}{Colors.ENDC}")

class PythonScheduler:
    """Pythonå®šæ™‚èª¿åº¦å™¨ - ä¿ç•™Pythonçš„èª¿åº¦å„ªå‹¢"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.scheduler_config = config.get("scheduler", {})
    
    async def setup_scheduler(self):
        """è¨­ç½®å®šæ™‚ä»»å‹™"""
        if not self.scheduler_config.get("enabled", False):
            logger.info("å®šæ™‚èª¿åº¦å™¨å·²ç¦ç”¨")
            return
        
        schedule_time = self.scheduler_config.get("time", "20:00")
        timezone = self.scheduler_config.get("timezone", "Asia/Shanghai")
        
        logger.info(f"ğŸ“… å®šæ™‚èª¿åº¦å·²å•Ÿç”¨: æ¯å¤© {schedule_time} ({timezone})")
        # é€™è£¡å¯ä»¥é›†æˆAPSchedulerç­‰Pythonèª¿åº¦åº«
        # æš«æ™‚ä¿ç•™æ¥å£ï¼Œå¾ŒçºŒæ“´å±•

async def main():
    """ä¸»å…¥å£å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="SubsCheck-Singbox v3.0 - Python+Goæ··åˆæ¶æ§‹")
    parser.add_argument("-f", "--config", default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("-s", "--subscription", default="subscription.txt", help="è¨‚é–±æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--compile-only", action="store_true", help="åƒ…ç·¨è­¯Goç¨‹åº")
    parser.add_argument("--python-scheduler", action="store_true", help="å•Ÿç”¨Pythonå®šæ™‚èª¿åº¦å™¨")
    parser.add_argument("--version", action="version", version="SubsCheck-Singbox v3.0")
    
    args = parser.parse_args()
    
    print("ğŸš€ SubsCheck-Singbox v3.0 - Python+Goæ··åˆæ¶æ§‹")
    print("=" * 60)
    print("ğŸ Pythonå±¤: é…ç½®ç®¡ç†ã€çµæœå±•ç¤ºã€å®šæ™‚èª¿åº¦")  
    print("âš¡ Goæ ¸å¿ƒ: é«˜æ€§èƒ½æ¸¬é€Ÿã€ä½µç™¼æ§åˆ¶ã€ä»£ç†æª¢æ¸¬")
    print("=" * 60)
    
    # åˆå§‹åŒ–Goæ¸¬é€Ÿå™¨
    checker = GoSubsChecker(args.config)
    
    # ç·¨è­¯Goç¨‹åº
    if not await checker.compile_go_if_needed():
        logger.error("âŒ Goç¨‹åºç·¨è­¯å¤±æ•—ï¼Œé€€å‡º")
        return 1
    
    if args.compile_only:
        logger.info("âœ… åƒ…ç·¨è­¯æ¨¡å¼å®Œæˆ")
        return 0
    
    # åˆå§‹åŒ–Pythonèª¿åº¦å™¨
    if args.python_scheduler:
        scheduler = PythonScheduler(checker.config)
        await scheduler.setup_scheduler()
        logger.info("Pythonå®šæ™‚èª¿åº¦å™¨å·²å•Ÿå‹•ï¼Œç¨‹åºå°‡ä¿æŒé‹è¡Œ...")
        try:
            while True:
                await asyncio.sleep(60)  # ä¿æŒé‹è¡Œ
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œé€€å‡ºç¨‹åº")
            return 0
    
    # åŸ·è¡Œæ¸¬é€Ÿ
    result = await checker.run_speed_test(args.subscription)
    
    # é¡¯ç¤ºçµæœ
    checker.display_results(result)
    
    return 0 if result.get("success") else 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(130)
    except Exception as e:
        logger.error(f"ç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)
